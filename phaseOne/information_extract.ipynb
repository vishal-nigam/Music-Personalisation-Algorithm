{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy  import array\n",
    "import librosa\n",
    "import os\n",
    "import ntpath\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tinytag import TinyTag\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from itertools import tee, islice, chain\n",
    "from math import atan2,degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocalsAndInstruments(stft,sr):\n",
    "    S_full, phase = librosa.magphase(stft)\n",
    "    # We'll compare frames using cosine similarity, and aggregate similar frames\n",
    "    # by taking their (per-frequency) median value.\n",
    "    #\n",
    "    # To avoid being biased by local continuity, we constrain similar frames to be\n",
    "    # separated by at least 2 seconds.\n",
    "    #\n",
    "    # This suppresses sparse/non-repetetitive deviations from the average spectrum,\n",
    "    # and works well to discard vocal elements.\n",
    "\n",
    "    S_filter = librosa.decompose.nn_filter(S_full,aggregate=np.median,metric='cosine',width=int(librosa.time_to_frames(2, sr=sr)))\n",
    "\n",
    "    # The output of the filter shouldn't be greater than the input\n",
    "    # if we assume signals are additive.  Taking the pointwise minimium\n",
    "    # with the input spectrum forces this.\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "    # We can also use a margin to reduce bleed between the vocals and instrumentation masks.\n",
    "    # Note: the margins need not be equal for foreground and background separation\n",
    "    margin_i, margin_v = 2, 10\n",
    "    power = 2\n",
    "\n",
    "    mask_i = librosa.util.softmask(S_filter,margin_i * (S_full - S_filter),power=power)\n",
    "\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter,margin_v * S_filter,power=power)\n",
    "\n",
    "    # Once we have the masks, simply multiply them with the input spectrum\n",
    "    # to separate the components\n",
    "    #S_foreground \n",
    "    return (S_full,(mask_i * S_full),(mask_v * S_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataFrameWithHeader(header):\n",
    "    return pd.DataFrame(columns=header)\n",
    "\n",
    "def appendMetadata(songname):\n",
    "    featurelist = []\n",
    "    tag = TinyTag.get(songname)\n",
    "    featurelist.append(ntpath.basename((songname)))\n",
    "    featurelist.append(tag.artist)\n",
    "    featurelist.append(tag.duration)\n",
    "    featurelist.append(tag.albumartist)\n",
    "    featurelist.append(tag.bitrate)\n",
    "    featurelist.append(tag.comment)\n",
    "    featurelist.append(tag.filesize)\n",
    "    featurelist.append(tag.genre)\n",
    "    featurelist.append(tag.title) \n",
    "    featurelist.append(tag.track) \n",
    "    featurelist.append(tag.samplerate) \n",
    "    featurelist.append(tag.track_total) \n",
    "    featurelist.append(tag.year)\n",
    "    return featurelist\n",
    "\n",
    "def get_Wav_from_Mp3(songname):\n",
    "    sound = AudioSegment.from_mp3(songname)\n",
    "    filename = \"final.wav\"\n",
    "    sound.export(filename, format=\"wav\")\n",
    "    return filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAudioInformation(filename):\n",
    "    featurelist = []\n",
    "    y, sr = librosa.load(filename, mono=True)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    full_spectrum,instruments,vocals = getVocalsAndInstruments(librosa.stft(y),sr)\n",
    "    tempo, beat_times = librosa.beat.beat_track(y)\n",
    "###-----------------------Audio Metadata-----13-----------------------------\n",
    "    featurelist = appendMetadata(songname)\n",
    "###-----------------------Audio Features----------------------28------------\n",
    "    featurelist.append(pickle.dumps(y,protocol = -1) )\n",
    "    featurelist.append(sr)\n",
    "    featurelist.append(np.mean(full_spectrum))\n",
    "    featurelist.append(np.mean(instruments))\n",
    "    featurelist.append(np.mean(vocals))\n",
    "    featurelist.append(pickle.dumps(chroma_stft,protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.spectral_centroid(y=y, sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.spectral_bandwidth(y=y, sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.spectral_rolloff(y=y, sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.zero_crossing_rate(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.mfcc(y=y, sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.rmse(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.chroma_cqt(y , sr=sr),protocol = -1)) \n",
    "    featurelist.append(pickle.dumps(librosa.feature.chroma_cens(y , sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.melspectrogram(y, sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.spectral_contrast(y , sr=sr),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.spectral_flatness(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.poly_features(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.tonnetz(y),protocol = -1))\n",
    "    tempogram1 = librosa.feature.tempogram(y)\n",
    "    featurelist.append(pickle.dumps(tempogram1,protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.onset.onset_detect(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.onset.onset_strength(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.onset.onset_strength_multi(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(beat_times,protocol = -1))\n",
    "    featurelist.append(pickle.dumps(tempo,protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.effects.hpss(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.effects.percussive(y),protocol = -1))\n",
    "    featurelist.append(pickle.dumps(librosa.feature.delta(tempogram1),protocol = -1))\n",
    "    \n",
    "    return featurelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename artist duration albumartist bitrate comment filesize genre title track samplerate track_total year audio_waveform sampling_rate full_spectrum_mean instruments_mean vocals_mean '\n",
    "fe_col_header = 'chroma_stft spectral_centroid spectral_bandwidth rolloff zero_crossing_rate mfcc rmse chroma_cqt chroma_cens melspectrogram spectral_contrast spectral_flatness poly tonal_centroid tempogram onset_detect onset_strength onset_strength_multi beat tempo harmonic_elements percussive_elements delta'\n",
    "header += fe_col_header\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInfo(directory_path,storage_path):\n",
    "    pathlist = Path(directory_path).glob('**/*.mp3')\n",
    "    df = generateDataFrameWithHeader(header)\n",
    "    sr_no = 0\n",
    "    for path in pathlist:\n",
    "        sr_no += 1\n",
    "        path_in_str = str(path)\n",
    "        songname = path_in_str.replace(os.sep, '/')\n",
    "\n",
    "        ###-----List to store all the metadata and other information for an audio file------\n",
    "        featurelist = []\n",
    "\n",
    "        ###-----MP3 file conersion to wave format for better analysis-------------\n",
    "        filename = get_Wav_from_Mp3(songname)\n",
    "\n",
    "        ###----------------storing  the audio file information --------------------\n",
    "        featurelist =  getAudioInformation(songname)\n",
    "\n",
    "        ###-------Storing the information-list  to  Pandas DataFarme--------------------\n",
    "        df.loc[sr_no] = featurelist\n",
    "    df.to_pickle(storage_path,protocol = -1)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_audio_directory_path = \"D:/learning/DataScience/data/musicFiles\" \n",
    "pickle_file_storage_path = \"D:/learning/DataScience/data/prj/featureExtraction/picklle_file/audio_information_extract_april20.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractInfo(mp3_audio_directory_path,pickle_file_storage_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
